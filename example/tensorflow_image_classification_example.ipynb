{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_image_classification_example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOy8z9OTfmCOBE06wNtbNl5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wayne0git/tensorflow_basic/blob/main/example/tensorflow_image_classification_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow Image Classification Example\n",
        "- https://learnopencv.com/tensorflow-lite-model-optimization-for-on-device-machine-learning/"
      ],
      "metadata": {
        "id": "5ILIeOFI7wdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "BOkOZAz372wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np          # 1.21.6"
      ],
      "metadata": {
        "id": "Q0rLtdPh72Ex"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf        # 2.8.0\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "taQ2ex6F8Dj6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Dense, BatchNormalization"
      ],
      "metadata": {
        "id": "qEOS_tAs8EOq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WMuWuvEgk2qo"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset\n",
        "- Cat vs Dog dataset from tfds"
      ],
      "metadata": {
        "id": "AfOL9M_b8GI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data with a split ratio of 0.7 (train) : 0.2 (validation) : 0.1 (test)\n",
        "(train_ds, val_ds, test_ds), info = tfds.load('cats_vs_dogs',\\\n",
        "                          split=['train[:70%]', 'train[70%:90%]', 'train[90%:]'],\\\n",
        "                          shuffle_files=True, as_supervised=True, with_info=True)"
      ],
      "metadata": {
        "id": "-mtMhu628M0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dataset number\n",
        "print(\"Training Images: %d\" % tf.data.experimental.cardinality(train_ds).numpy())\n",
        "print(\"Validation Images: %d\" % tf.data.experimental.cardinality(val_ds).numpy())\n",
        "print(\"Test Images: %d\" % tf.data.experimental.cardinality(test_ds).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THRp9jEZ9tiq",
        "outputId": "efbeec66-40c0-4abe-c85e-c6cef4f8297a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Images: 16283\n",
            "Validation Images: 4653\n",
            "Test Images: 2326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check label info\n",
        "print(\"Number of  Classes: \" + str(info.features['label'].num_classes))\n",
        "print(\"Classes : \" + str(info.features['label'].names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fsEqwXh9PWQ",
        "outputId": "96ec05f3-3b35-453f-b126-1b376266319a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of  Classes: 2\n",
            "Classes : ['cat', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check image data\n",
        "vis = tfds.visualization.show_examples(train_ds, info)"
      ],
      "metadata": {
        "id": "PTqVRCY_9mmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "YxksYc_d-Rw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter\n",
        "N_BATCH = 16\n",
        "IMG_SIZE = [224, 224]"
      ],
      "metadata": {
        "id": "51o96zyA-BaP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize image data\n",
        "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, IMG_SIZE), y))\n",
        "val_ds = val_ds.map(lambda x, y: (tf.image.resize(x, IMG_SIZE), y))\n",
        "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, IMG_SIZE), y))"
      ],
      "metadata": {
        "id": "1Am--J0s-b2v"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buffering the dataset\n",
        "train_ds = train_ds.cache().batch(N_BATCH).prefetch(buffer_size=10)\n",
        "val_ds = val_ds.cache().batch(N_BATCH).prefetch(buffer_size=10)\n",
        "test_ds = test_ds.cache().batch(N_BATCH).prefetch(buffer_size=10)"
      ],
      "metadata": {
        "id": "275kAbma-nqx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model"
      ],
      "metadata": {
        "id": "ivN-iRxv-2Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter\n",
        "INPUT_SIZE = (224, 224, 3)"
      ],
      "metadata": {
        "id": "XLOlxhuq_AEp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EfficientNetB0\n",
        "eff_net = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_shape=INPUT_SIZE, pooling='max')"
      ],
      "metadata": {
        "id": "Ubc3lPoc-3ql"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding layer for transfer learning\n",
        "x = Dense(512, activation='relu')(eff_net.output)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "predictions = Dense(2, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "-b6E0kxn_mXA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build image classification model\n",
        "model = Model(inputs=eff_net.input, outputs=predictions)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "g3NSMg0Q_wOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "WVjD3wo8AIhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter\n",
        "MODEL_FPATH = '/content/train/model.h5'\n",
        "N_EPOCH = 15"
      ],
      "metadata": {
        "id": "gmH0rSVbAU2B"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback to save best model\n",
        "model_save = tf.keras.callbacks.ModelCheckpoint(MODEL_FPATH,\n",
        "                         monitor=\"val_accuracy\",\n",
        "                         verbose=0,\n",
        "                         save_best_only=True,\n",
        "                         save_weights_only=False,\n",
        "                         mode=\"max\",\n",
        "                         save_freq=\"epoch\")"
      ],
      "metadata": {
        "id": "jajOYpd-AKBS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback to Reduce LR Callback reduces the learning rate if validation loss remains the same for 3 consecutive epochs.\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', \n",
        "                         factor=0.1, \n",
        "                         patience=3, \n",
        "                         verbose=1, \n",
        "                         min_delta=5*1e-3,\n",
        "                         min_lr=5*1e-9,)"
      ],
      "metadata": {
        "id": "ylNitMNEAu74"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, epochs=N_EPOCH, \n",
        "     steps_per_epoch=(len(train_ds)//N_BATCH),\n",
        "     validation_data=val_ds, validation_steps=(len(val_ds)//N_BATCH),\n",
        "     shuffle=False, callbacks=[reduce_lr, model_save])"
      ],
      "metadata": {
        "id": "sSatMGtiBCGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Model"
      ],
      "metadata": {
        "id": "fzE2TX0JBPxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, baseline_model_accuracy = model.evaluate(test_ds, verbose=0)\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)"
      ],
      "metadata": {
        "id": "0qBh-7UFBRyt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}